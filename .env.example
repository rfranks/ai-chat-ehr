# Copy this file to `.env` before running docker compose commands.
# Each variable includes guidance on how it is used and whether it is required.

# ---------------------------------------------------------------------------
# Docker build configuration
# ---------------------------------------------------------------------------
# Base image used by Docker builds for all services. Change only if you build
# a custom base image locally.
BASE_IMAGE=ai-chat-ehr-base:latest

# ---------------------------------------------------------------------------
# Chain executor outbound HTTP configuration
# ---------------------------------------------------------------------------
# URL for the prompt catalog service exposed within docker-compose networking.
CHAIN_EXECUTOR_PROMPT_CATALOG_URL=http://prompt-catalog:8001
# URL for the patient context service exposed within docker-compose networking.
CHAIN_EXECUTOR_PATIENT_CONTEXT_URL=http://patient-context:8002
# Timeout (in seconds) for outbound HTTP requests made by the chain executor.
CHAIN_EXECUTOR_HTTP_TIMEOUT=10

# ---------------------------------------------------------------------------
# Default model selection
# ---------------------------------------------------------------------------
# Provider that should be used when a request does not explicitly specify one.
DEFAULT_MODEL__PROVIDER=openai
# Model identifier that should be used by default for the provider above.
DEFAULT_MODEL__NAME=gpt-3.5-turbo
# Sampling temperature applied to default model invocations (0.0-2.0).
DEFAULT_MODEL__TEMPERATURE=0.7

# ---------------------------------------------------------------------------
# Provider credentials (replace with real values as needed)
# Only populate the block for providers you plan to use.
# ---------------------------------------------------------------------------
# Required for OpenAI requests. Obtain from https://platform.openai.com/.
OPENAI_API_KEY=your-openai-api-key
# Optional OpenAI organization override when using enterprise accounts.
OPENAI_ORGANIZATION=
# Optional OpenAI project override for the unified API.
OPENAI_PROJECT=
# Optional base URL override for Azure OpenAI or API gateway proxies.
OPENAI_BASE_URL=

# Azure OpenAI configuration. Required when DEFAULT_MODEL__PROVIDER=azure.
AZURE_API_KEY=
AZURE_ENDPOINT=
AZURE_DEPLOYMENT_NAME=
AZURE_API_VERSION=

# Anthropic Claude configuration. Required when DEFAULT_MODEL__PROVIDER=anthropic.
ANTHROPIC_API_KEY=
# Optional Anthropic API base URL override (e.g., for on-prem gateways).
ANTHROPIC_BASE_URL=

# Vertex AI configuration. Required when DEFAULT_MODEL__PROVIDER=vertex.
# Google Cloud project containing the Vertex AI deployment.
VERTEX_PROJECT_ID=
# Region where the Vertex AI model is deployed (e.g., us-central1).
VERTEX_LOCATION=
# Absolute path to the Google service account JSON file used for Vertex.
VERTEX_CREDENTIALS_FILE=
# Model ID or publisher/model alias to invoke via Vertex AI.
VERTEX_MODEL=

# ---------------------------------------------------------------------------
# Google Cloud credentials
# ---------------------------------------------------------------------------
# Absolute path to a service account key file shared by Google integrations
# (e.g., Vertex AI, Firestore). Must be readable from within Docker containers.
GOOGLE_APPLICATION_CREDENTIALS=/secrets/service-account.json

# ---------------------------------------------------------------------------
# Firestore configuration
# ---------------------------------------------------------------------------
# Google Cloud project ID where Firestore is hosted.
FIRESTORE_PROJECT_ID=

# ---------------------------------------------------------------------------
# Relational database configuration
# ---------------------------------------------------------------------------
# SQLAlchemy-compatible database URL for application persistence. Provide the
# driver, credentials, host, port, and database (e.g., postgresql+psycopg://user:pass@db:5432/app).
DATABASE_URL=

# ---------------------------------------------------------------------------
# Example data store configuration
# ---------------------------------------------------------------------------
# Redis connection string used by background workers and caches.
REDIS_URL=redis://redis:6379/0

# ---------------------------------------------------------------------------
# Anonymizer service configuration
# ---------------------------------------------------------------------------
# Data source used to fetch patient documents. Use "fixtures" to read the local
# JSON files included with the repository or "credentials" to connect to a real
# Firestore project using service account credentials.
ANONYMIZER_FIRESTORE_SOURCE=fixtures
# Directory containing patient fixture JSON files when
# ANONYMIZER_FIRESTORE_SOURCE=fixtures.
ANONYMIZER_FIRESTORE_FIXTURES_DIR=services/anonymizer/firestore_fixtures/patients
# Absolute path to the Google service account JSON file used when
# ANONYMIZER_FIRESTORE_SOURCE=credentials.
ANONYMIZER_FIRESTORE_CREDENTIALS=/secrets/service-account.json
# SQLAlchemy-compatible Postgres DSN used by the anonymizer storage layer for
# persisting anonymized patient rows when ANONYMIZER_STORAGE_MODE=database.
ANONYMIZER_POSTGRES_DSN=postgresql+psycopg://user:pass@db:5432/anonymizer
# Storage mode for anonymized rows. Use "database" to insert directly into
# Postgres or "sqlfile" to emit INSERT statements for review.
ANONYMIZER_STORAGE_MODE=database
# Filesystem path where INSERT statements are written when the storage mode is
# set to "sqlfile".
ANONYMIZER_STORAGE_SQL_PATH=anonymizer_dry_run.sql
